{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Activation steering with TransformerLens and gpt2-xl\n",
    "\n",
    "This notebook shows how to access and modify internal model activations using the transformer lens library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformer_lens import HookedTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-xl into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "# load transformer lens model\n",
    "model = HookedTransformer.from_pretrained_no_processing(\"gpt2-xl\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_love.shape: torch.Size([1, 2, 1600])\n",
      "act_hate.shape: torch.Size([1, 3, 1600])\n"
     ]
    }
   ],
   "source": [
    "# define what layer/module you want information from and get the internal activations\n",
    "layer_id = 5\n",
    "cache_name = f\"blocks.{layer_id}.hook_resid_post\" # we do activation steering on the activation (the output) of the residual layer\n",
    "\n",
    "_, cache = model.run_with_cache(\"Love\")\n",
    "act_love = cache[cache_name]\n",
    "_, cache = model.run_with_cache(\"Hate\")\n",
    "act_hate = cache[cache_name]\n",
    "\n",
    "print(f\"act_love.shape: {act_love.shape}\")\n",
    "print(f\"act_hate.shape: {act_hate.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see by looking at the shape of the activation tensors, the input \"sentences\" are tokenized into different numbers of tokens. To make this into a vector we only take the numerical values of the last token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "steering_vec.shape:  torch.Size([1, 1, 1600])\n",
      "length steering_vec: 79.89\n"
     ]
    }
   ],
   "source": [
    "# define the steering vector\n",
    "steering_vec = act_love[:,-1:,:]-act_hate[:,-1:,:]\n",
    "print(f\"steering_vec.shape:  {steering_vec.shape}\")\n",
    "print(f\"length steering_vec: {steering_vec.norm():.2f}\")\n",
    "\n",
    "# reset the steering vector length to 1\n",
    "steering_vec /= steering_vec.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the activation steering funtion\n",
    "def act_add(steering_vec):\n",
    "    def hook(activation, hook):\n",
    "        return activation + steering_vec\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We previously used the function `run_with_cache` to get the internal activations. This function adds PyTorch hooks before running the model and removes them afterwards.\n",
    "There is also the function `run_with_hooks` for which you can set your own hook functions. However I did not find a function `generate_with_hooks`.\n",
    "\n",
    "If we want to generate new text, the model needs to repeatedly perform a forward pass and we want our activation addition to happen in each forward pass. We consequently need to set a hook that does the activation addition. After we generated our text it is important to remove the hook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ed6d2eed4ea4e66a5db4ddd39bc69ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think dogs are  Love is Love Love Love Love Love Love Love Love\n",
      "--------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6281ede59f9040de8171c51de45743fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think dogs are icky.\n",
      ".ate\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"I think dogs are \"\n",
    "\n",
    "# generate text while steering in positive direction\n",
    "coeff = 60\n",
    "model.add_hook(name=cache_name, hook=act_add(coeff*steering_vec))\n",
    "print(model.generate(test_sentence, max_new_tokens=10, do_sample=False))\n",
    "model.reset_hooks()\n",
    "print(\"-\"*20)\n",
    "\n",
    "# generate text while steering in negative direction\n",
    "coeff = -70\n",
    "test_sentence = \"I think dogs are \"\n",
    "model.add_hook(name=cache_name, hook=act_add(coeff*steering_vec))\n",
    "print(model.generate(test_sentence, max_new_tokens=10, do_sample=False))\n",
    "model.reset_hooks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0dbd3537b449b89e0c3567ef28eb88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I think dogs are Â the most misunderstood animal. They are so misunderstood\n"
     ]
    }
   ],
   "source": [
    "# generate text without steering\n",
    "print(model.generate(test_sentence, max_new_tokens=10, do_sample=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
